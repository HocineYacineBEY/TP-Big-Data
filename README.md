Projet Big Data â€“ Analyse Comparative du Clustering K-means: Scikit-learn vs Apache Spark

Ce projet propose une Ã©tude approfondie et expÃ©rimentale de lâ€™algorithme de clustering K-means, comparÃ© dans deux environnements de calcul complÃ©mentaires :
Scikit-learn â†’ calcul local en mÃ©moire
Apache Spark (PySpark) â†’ calcul distribuÃ© pour environnements Big Data

Lâ€™objectif est dâ€™Ã©valuer comment lâ€™architecture de calcul influence : les performances temporelles, lâ€™utilisation des ressources (CPU / RAM), la qualitÃ© du clustering, et la scalabilitÃ© sur des volumes de donnÃ©es croissants.

ğŸ“˜ Contenu du notebook

Le notebook fourni reproduit lâ€™ensemble du workflow dâ€™un projet Big Data :

ğŸ”§ PrÃ©traitement des donnÃ©es (Normalisation, encodage catÃ©goriel, correction via One-Hot Encoding (important pour le dataset Adult)

ğŸŒ€ ImplÃ©mentation du clustering K-means

Version Scikit-learn

Version PySpark

ğŸ“Š Mesures et analyses expÃ©rimentales: Temps dâ€™exÃ©cution, consommation CPU / RAM, inertie et silhouette Score

ğŸ“ˆ Jeux de donnÃ©es testÃ©s:
Wine Quality (petit)
Adult Dataset (moyen)
DonnÃ©es synthÃ©tiques Scikit-learn : 50k, 100k, 200k
DonnÃ©es Spark : 100k et 300k en 10 dimensions

ğŸ¨ Visualisations
Graphiques comparatifs
Analyse des tendances
InterprÃ©tation des rÃ©sultats

ğŸ¯ Objectifs pÃ©dagogiques et scientifiques
Comprendre le comportement rÃ©el de K-means en local vs distribuÃ©
Identifier les limites du calcul local face au volume et Ã  la dimension
Analyser lâ€™importance du prÃ©traitement (normalisation, encodage correct)
Ã‰valuer la scalabilitÃ© de K-means
DÃ©finir les contextes dâ€™utilisation appropriÃ©s pour Scikit-learn et Spark

âš ï¸ Point mÃ©thodologique clÃ©

Lors du traitement du dataset Adult, un premier encodage naÃ¯f des variables catÃ©gorielles (encodage par entiers) a gÃ©nÃ©rÃ© :
des distances artificielles,
un clustering non interprÃ©table.

La correction par One-Hot Encoding a rÃ©tabli :
la cohÃ©rence gÃ©omÃ©trique des donnÃ©es,
la validitÃ© mathÃ©matique du clustering,
l'interprÃ©tabilitÃ© des rÃ©sultats.

ğŸ› ï¸ Technologies utilisÃ©es
Python 3
Scikit-learn
Apache Spark (PySpark)
Pandas / NumPy
Matplotlib

ğŸ“ Fichier fourni

TPbigdata(3).ipynb â€” Notebook complet contenant : ImplÃ©mentations, mesures expÃ©rimentales, visualisations, analyses.

ğŸ“ Contexte
Projet rÃ©alisÃ© dans le cadre du module Data Science â€“ Master IngÃ©nierie des SystÃ¨mes Complexes - Transformation NumÃ©rique pour l'Industrie.
